### **2. Componentes Fundamentais da Estrutura DU: As Etapas do Processamento Inteligente de Documentos**

A eficácia do **UiPath Document Understanding (DU)** reside na sua arquitetura modular, que divide o complexo processo de extração de dados de documentos em etapas gerenciáveis. Cada componente tem um papel específico e, juntos, eles formam um fluxo de trabalho poderoso e adaptável. O framework do Document Understanding é encontrado principalmente nos pacotes **UiPath.DocumentUnderstanding.Activities** (moderno, para projetos Windows e Multiplataforma) e **UiPath.IntelligentOCR.Activities** (para projetos Windows ou Windows-Legacy). É importante notar que esses dois pacotes não devem ser usados juntos no mesmo projeto.

Vamos explorar cada um desses componentes em detalhes:

#### **2.1. Taxonomia**

A **Taxonomia** é o ponto de partida do processo de Document Understanding. É aqui que você **define o que você espera dos seus documentos**.

*   **O que é:** É o componente usado para **definir os tipos de documentos** que o robô irá processar (por exemplo, "Fatura", "Contrato", "Recibo") e, crucialmente, **quais informações específicas (campos) você deseja extrair** de cada um desses tipos. Pense na taxonomia como o "dicionário" e a "estrutura" de dados que o robô usará para entender seus documentos. Ela formaliza essas informações em uma estrutura de taxonomia dedicada.
*   **Como funciona:** Essas definições de metadados são gerenciadas através do **Gerenciador de Taxonomia**. Ao configurar a taxonomia, você está essencialmente dizendo ao sistema: "Este é um documento de tipo X, e dele eu preciso extrair o campo Y, o campo Z, etc."
*   **Finalidade:** Responde à pergunta: "**Quais documentos precisam ser processados e quais dados são exigidos deles?**". Sem uma taxonomia bem definida, o robô não saberia o que procurar nos documentos.

#### **2.2. Digitalização (Digitization)**

A **Digitalização** é a primeira etapa aplicada em arquivos que precisam ser processados pelo Document Understanding.

*   **O que é:** É o processo de **transformar um arquivo de entrada em conteúdo legível por máquina**, extraindo seu texto e estrutura para que possa ser compreendido e processado pelo robô.
*   **Saídas:** A digitalização produz duas saídas principais:
    *   O **texto** completo do arquivo processado, armazenado em uma variável do tipo *string*.
    *   O **Modelo de Objeto de Documento (DOM)**, que é um objeto JSON. O DOM contém informações básicas sobre o arquivo (como nome, tipo de conteúdo, tamanho do texto, número de páginas) e informações detalhadas (como rotação da página, idioma detectado, conteúdo e coordenadas para cada palavra identificada no arquivo).
*   **Atividade Principal:** A digitalização é realizada usando a atividade `Digitize Document`.
*   **Não é OCR (mas pode usá-lo):** É importante entender que a digitalização *não é o mesmo que OCR*. Embora relacionada, a atividade `Digitize Document` só utiliza um mecanismo de OCR quando realmente necessário, ou seja:
    *   Para **arquivos que são imagens** (formatos suportados incluem .png, .jpe, .jpg, .jpeg, .tiff, .tif, .bmp; para TIFFs multipágina, o OCR é aplicado por página).
    *   Para **páginas PDF que não possuem conteúdo legível por máquina** ou que contêm imagens que cobrem uma área significativa da página.
    *   Se a propriedade `ForceApplyOCR` da atividade `Digitize Document` for definida como `True` (recomendado para casos onde PDFs nativos têm conteúdo ilegível que não corresponde ao visível).
*   **Mecanismos de OCR Disponíveis:** A atividade `Digitize Document` exige a seleção de um mecanismo de OCR. Várias opções estão disponíveis:
    *   **UiPath Extended Languages OCR**
    *   **UiPath Document OCR**
    *   **OmniPage OCR**
    *   **Google Cloud Vision OCR**
    *   **Microsoft Azure Computer Vision OCR**
    *   **Microsoft OCR**
    *   **Tesseract OCR**
    *   *Observação:* O **OCR para Chinês, Japonês e Coreano** da UiPath será descontinuado a partir de janeiro de 2025; recomenda-se usar o UiPath Extended Languages OCR.
*   **Limitações:** Existem limites de 160 MB para o tamanho do arquivo e um máximo de 500 páginas por documento para digitalização.
*   **Boas Práticas:** É altamente recomendável testar diferentes mecanismos de OCR e suas configurações (como `Perfil`, `Escala`, `Idioma`) para determinar qual funciona melhor para seu projeto específico.

#### **2.3. Classificação de Documentos**

A **Classificação de Documentos** é o componente da estrutura que ajuda a **identificar quais tipos de arquivos** o UiPath Robot está processando.

*   **O que é:** É o processo de **determinar automaticamente quais tipos de documentos** definidos na Taxonomia do seu projeto são encontrados em um arquivo digitalizado.
*   **Tipos de Classificação:**
    *   Se um arquivo contiver **um único tipo de documento lógico** (ex: uma fatura completa), a classificação deve retornar um único resultado.
    *   Se um arquivo contiver **vários tipos de documentos lógicos** (ex: faturas e prontuários médicos no mesmo arquivo, em diferentes intervalos de páginas), a classificação deve retornar múltiplos resultados, cada um correspondendo ao intervalo de páginas correto.
*   **Quando Usar:** A classificação é **fortemente recomendada** se o projeto lidar com dois ou mais tipos de documentos que não podem ser distinguidos antes do processamento, ou se os arquivos podem conter múltiplos tipos de documentos distintos dentro deles. Não é necessária se todos os arquivos são do mesmo tipo e uma única instância por arquivo.
*   **Como Usar:** A classificação é realizada através da atividade **`Classify Document Scope`**.
    *   Esta atividade de escopo configura e executa um ou mais algoritmos de classificação (chamados **classificadores**).
    *   Ela fornece aos classificadores as configurações necessárias, aceita um ou mais classificadores, permite filtragem por tipo de documento, mapeamento de taxonomia e limites mínimos de confiança.
    *   A **ordem dos classificadores** dentro do `Classify Document Scope` é importante: eles são executados com prioridade, da esquerda para a direita. Um resultado de classificação é aceito se o tipo de documento for aceitável E a confiança for igual ou superior ao limite mínimo definido. Os classificadores subsequentes são executados apenas nos intervalos de páginas que permaneceram não classificados pelos classificadores anteriores.
*   **Classificadores Disponíveis:** Os classificadores podem ser encontrados nos pacotes **UiPath.IntelligentOCR.Activities** ou **UiPath.DocumentUnderstanding.ML.Activities**.
    *   **Classificador Baseado em Palavra-chave (`Keyword Based Classifier`)**: Um classificador simples que busca sequências de *strings* repetidas (palavras-chave) para classificar documentos. Ele se baseia na premissa de que os documentos têm títulos com baixa variação. A confiança é calculada com base na proximidade da correspondência ao início do documento e na frequência com que foi confirmada nos dados de aprendizado. É ideal quando os arquivos contêm *apenas um tipo de documento* cada e a evidência está nas *três primeiras páginas*.
    *   **Intelligent Keyword Classifier**: Usa o vetor de palavras aprendido a partir de arquivos de determinados tipos de documentos para classificar. Baseia-se na repetição de conteúdo e pode realizar **divisão de arquivos**, ou seja, pode relatar mais de uma classe para um determinado arquivo em intervalos de páginas separados. Use quando os arquivos contêm *um ou mais tipos de documentos em um único arquivo* e os tipos de documento são relativamente fáceis de diferenciar pelo conteúdo. Requer uma **Chave de API do Automation Cloud Document Understanding** ou hospedagem local no AI Center.
    *   **Machine Learning Classifier**: Utiliza um modelo de *machine learning* implantado como uma habilidade de ML no AI Center para classificação. É configurado usando um modelo de classificador no AI Center (como o pacote `DocumentClassifier`) e a taxonomia. É indicado quando você precisa classificar documentos únicos sem necessidade de divisão ou quando tipos de documentos personalizados são muito semelhantes, pois pode diferenciá-los mais facilmente do que o `Intelligent Keyword Classifier`. Suporta diversos tipos pré-treinados, como faturas, recibos, passaportes, etc..
    *   **Classificador Generativo (`Generative Classifier`)**: Emprega **IA generativa** para classificar documentos com base em **descrições dos tipos de documentos** que você deseja classificar. Você o configura adicionando-o ao `Classify Document Scope` e fornecendo descrições claras e em linguagem natural para cada tipo de documento. É adequado para documentos não estruturados e com conteúdo diversificado, onde você pode descrever claramente os tipos de documentos. Ao otimizar a classificação de um grande número de documentos, é importante fornecer o **máximo de contexto possível** nas descrições de cada tipo de documento.
    *   **Classificador do FlexiCapture**.
*   **Classificadores Personalizados:** É possível construir seu próprio Classificador utilizando as classes abstratas dos pacotes **`UiPath.DocumentProcessing.Contracts`** e **`UiPath.OCR.Contracts`**, permitindo implementar qualquer algoritmo que se adapte ao seu caso de uso.

#### **2.4. Validação da Classificação de Documentos**

Esta é uma etapa **opcional**, mas pode ser crucial para garantir a precisão.

*   **O que é:** Um componente usado para **auxiliar na validação manual e correção dos resultados de classificação automática** e, futuramente, na divisão de documentos.
*   **Finalidade:** Responde à pergunta: "**A classificação prevista está correta? É assim que é possível revisá-la e corrigi-la.**". Permite que um operador humano revise e ajuste as classificações feitas pelo robô.
*   **Ferramenta:** A interface para essa validação é a **`Classification Station`**.

#### **2.5. Treinamento em Classificação de Documentos**

Esta etapa fecha o *loop* de aprendizado.

*   **O que é:** É o processo de **passar as informações validadas por humanos de volta para os classificadores**, para que eles possam usar esses dados para melhorar suas previsões futuras.
*   **Como funciona:** À medida que os humanos corrigem as classificações, o robô "aprende" com esses ajustes, tornando-se mais inteligente e preciso ao longo do tempo. Atividades como **`Train Classifiers Scope`** e **`Machine Learning Classifier Trainer`** são usadas aqui. O `Intelligent Keyword Classifier Trainer` também pode ser usado.

#### **2.6. Extração de Dados**

A **Extração de Dados** é o coração do Document Understanding, onde as informações valiosas são realmente capturadas.

*   **O que é:** É o componente da estrutura que ajuda a **identificar e capturar informações muito específicas** que você definiu na taxonomia para seus tipos de documentos. Somente os campos definidos na **Taxonomia** podem ser direcionados para extração automática.
*   **Fluxo de Trabalho:** A etapa de extração de dados garante que os extratores configurados sejam acionados na ordem correta, para a lista correta de campos e para o intervalo de páginas correto do arquivo. Se um arquivo contiver vários tipos de documentos em diferentes intervalos de páginas, a extração de dados é recomendada para ser executada múltiplas vezes, uma para cada resultado de classificação e seu respectivo intervalo de páginas.
*   **Como Usar:** A extração de dados é feita por meio da atividade **`Data Extraction Scope`**.
    *   Esta atividade de escopo configura e executa um ou mais algoritmos de extração de dados (chamados **extratores**).
    *   Ela fornece aos extratores as configurações e entradas necessárias, aceita um ou mais extratores, permite ativação no nível do campo, mapeamento de taxonomia e limites mínimos de confiança.
    *   Você pode **misturar e combinar extratores**, usando diferentes extratores para diferentes campos, e até implementar **regras de "retorno"** (se um extrator não encontrar um valor aceitável, um extrator de backup pode ser ativado).
    *   A **ordem dos extratores** no `Data Extraction Scope` é importante: eles são executados com prioridade, da esquerda para a direita. Um valor extraído é aceito apenas se sua confiança atender ao limite mínimo. Extratores subsequentes são executados apenas para campos que ainda não obtiveram um resultado aceitável dos extratores anteriores e para o intervalo de páginas de classificação fornecido.
*   **Extratores Disponíveis:** Os extratores podem ser encontrados nos pacotes **UiPath.IntelligentOCR.Activities** ou **UiPath.DocumentUnderstanding.ML.Activities**.
    *   **Extrator Baseado em Regex (`Regex Based Extractor`)**.
    *   **Form Extractor**.
    *   **Machine Learning Extractor**.
    *   **Extrator Generativo (`Generative Extractor`)**: Utiliza **IA generativa**. Possui limitações de no máximo 50 solicitações e a resposta (Conclusão) tem um limite de 700 palavras.
        *   **Boas Práticas para o Extrator Generativo:**
            *   **Linguagem Precisa:** Use linguagem direta e precisa em seus *prompts* para reduzir a ambiguidade e aumentar a precisão.
            *   **Formato de Saída Específico:** Peça ao extrator para retornar a resposta em um formato padronizado (ex: `yyyy-mm-dd` para datas, `##,###.##` para números) para simplificar o processamento posterior.
            *   **Opções Esperadas:** Forneça um conjunto conhecido de opções possíveis para a resposta (ex: "Estado Civil: Casado, Solteiro...") para aumentar a precisão.
            *   **Passo a Passo:** Divida perguntas complexas em etapas simples, quase como um programa de computador, para maximizar a precisão.
            *   **Evite Problemas Aritméticos ou Lógicos:** Não peça ao extrator para realizar cálculos (soma, multiplicação) ou lógica complexa (se-então-senão), pois os robôs são mais rápidos, precisos e eficientes para essas operações.
            *   **Tabelas:** Extrair tabelas é um desafio para o extrator Generativo, que opera em sequências lineares de texto e não compreende informações visuais bidimensionais. Para tabelas menores, você pode pedir para retornar colunas separadamente ou cada linha como um objeto JSON.
            *   **Nível de Confiança:** Modelos de IA Generativa não fornecem níveis de confiança. Para detectar erros, uma boa prática é fazer a mesma pergunta de várias maneiras diferentes; se as respostas convergem, a probabilidade de erro é baixa.
    *   **Intelligent Form Extractor**.
    *   **FlexiCapture Extractor**.
*   **Extratores Personalizados:** Assim como os classificadores, é possível construir extratores personalizados utilizando as classes abstratas dos `Contratos de Processamento de Documentos`.

#### **2.7. Validação de Extração de Dados**

Esta etapa é **opcional, mas altamente recomendada** para garantir a qualidade dos dados.

*   **O que é:** É uma etapa de **revisão manual** onde trabalhadores do conhecimento podem revisar os resultados extraídos automaticamente e corrigi-los quando necessário.
*   **Finalidade:** Garante que os dados estruturados agora disponíveis estejam **100% corretos**.
*   **Quando Usar:** É altamente recomendado quando você precisa de **100% de precisão** nos dados, não tem outra forma de verificar as informações extraídas automaticamente (como compará-las com um banco de dados) ou não possui verificações sintéticas suficientes para a consistência dos dados (ex: verificar se os itens de linha somam o total).
*   **Ferramenta:** A validação pode ser feita por entrada humana através da **`Validation Station`**.
    *   Pode ser uma atividade assistida (`Present Validation Station`).
    *   Pode ser uma tarefa no **UiPath Action Center** (`Create Document Validation Action` e `Wait For Document Validation Action And Resume`).
*   **Considerações:** É fundamental sempre verificar a **Confiança de Extração** e a **Confiança de OCR** de um valor antes de tomar uma decisão.

#### **2.8. Treinamento em Extração de Dados**

Semelhante ao treinamento de classificação, este componente otimiza o desempenho dos extratores.

*   **O que é:** É usado para **passar os dados extraídos validados por humanos de volta para os extratores**, permitindo que eles melhorem suas previsões de extração futuras.
*   **Como funciona:** A cada correção humana, os extratores aprendem e se tornam mais precisos ao longo do tempo. Atividades como **`Train Extractors Scope`** e **`Machine Learning Extractor Trainer`** são utilizadas nesta etapa.
